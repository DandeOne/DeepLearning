{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tensorflow 2.0.0 and mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking into the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21b8eb08>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Reshape,Flatten\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "codings_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Sequential()\n",
    "generator.add(Dense(100, activation=\"relu\", input_shape=[codings_size]))\n",
    "generator.add(Dense(150,activation='relu'))\n",
    "generator.add(Dense(784, activation=\"sigmoid\")) # 28*28 = 784\n",
    "generator.add(Reshape([28,28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "discriminator.add(Flatten(input_shape=[28,28]))\n",
    "discriminator.add(Dense(150,activation='relu'))\n",
    "discriminator.add(Dense(100,activation='relu'))\n",
    "discriminator.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (None, 28, 28)            143634    \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 1)                 132951    \n",
      "=================================================================\n",
      "Total params: 276,585\n",
      "Trainable params: 143,634\n",
      "Non-trainable params: 132,951\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 150)               15150     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 784)               118384    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 28, 28)            0         \n",
      "=================================================================\n",
      "Total params: 143,634\n",
      "Trainable params: 143,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN.layers[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0223 22:26:12.024759  2536 training.py:2090] Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 150)               117750    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 265,902\n",
      "Trainable params: 132,951\n",
      "Non-trainable params: 132,951\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN.layers[1].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_train = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(data_to_train).shuffle(buffer_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on Epoch 1\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 2\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 3\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 4\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 5\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 6\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 7\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 8\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 9\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 10\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 11\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 12\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 13\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 14\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 15\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 16\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 17\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 18\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 19\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "Currently on Epoch 20\n",
      "\tCurrently on batch number 100 of 1875\n",
      "\tCurrently on batch number 200 of 1875\n",
      "\tCurrently on batch number 300 of 1875\n",
      "\tCurrently on batch number 400 of 1875\n",
      "\tCurrently on batch number 500 of 1875\n",
      "\tCurrently on batch number 600 of 1875\n",
      "\tCurrently on batch number 700 of 1875\n",
      "\tCurrently on batch number 800 of 1875\n",
      "\tCurrently on batch number 900 of 1875\n",
      "\tCurrently on batch number 1000 of 1875\n",
      "\tCurrently on batch number 1100 of 1875\n",
      "\tCurrently on batch number 1200 of 1875\n",
      "\tCurrently on batch number 1300 of 1875\n",
      "\tCurrently on batch number 1400 of 1875\n",
      "\tCurrently on batch number 1500 of 1875\n",
      "\tCurrently on batch number 1600 of 1875\n",
      "\tCurrently on batch number 1700 of 1875\n",
      "\tCurrently on batch number 1800 of 1875\n",
      "TRAINING COMPLETE\n"
     ]
    }
   ],
   "source": [
    "#Code from Hands-On book\n",
    "generator, discriminator = GAN.layers\n",
    "\n",
    "# For every epoch\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Currently on Epoch {epoch+1}\")\n",
    "    i = 0\n",
    "    # For every batch in the dataset\n",
    "    for X_batch in dataset:\n",
    "        i=i+1\n",
    "        if i%100 == 0:\n",
    "            print(f\"\\tCurrently on batch number {i} of {len(data_to_train)//batch_size}\")\n",
    "        #####################################\n",
    "        ## TRAINING THE DISCRIMINATOR ######\n",
    "        ###################################\n",
    "        \n",
    "        # Create Noise\n",
    "        noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "        \n",
    "        # Generate numbers based just on noise input\n",
    "        gen_images = generator(noise)\n",
    "        \n",
    "        # Concatenate Generated Images against the Real Ones\n",
    "        # TO use tf.concat, the data types must match!\n",
    "        X_fake_vs_real = tf.concat([gen_images, tf.dtypes.cast(X_batch,tf.float32)], axis=0)\n",
    "        \n",
    "        # Targets set to zero for fake images and 1 for real images\n",
    "        y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "        \n",
    "        # This gets rid of a Keras warning\n",
    "        discriminator.trainable = True\n",
    "        \n",
    "        # Train the discriminator on this batch\n",
    "        discriminator.train_on_batch(X_fake_vs_real, y1)\n",
    "        \n",
    "        \n",
    "        #####################################\n",
    "        ## TRAINING THE GENERATOR     ######\n",
    "        ###################################\n",
    "        \n",
    "        # Create some noise\n",
    "        noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "        \n",
    "        # We want discriminator to belive that fake images are real\n",
    "        y2 = tf.constant([[1.]] * batch_size)\n",
    "        \n",
    "        # Avois a warning, weights are frozen so backpropagation only affects the weights of the generator\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        GAN.train_on_batch(noise, y2)\n",
    "        \n",
    "print(\"TRAINING COMPLETE\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal(shape=[1, codings_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 100])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17e505c0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = generator(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x180ccb70>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a56cb70>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(generator(tf.random.normal(shape=[1,codings_size]))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator creates everytime the same image. That is an example of mode collapse which model learnt to create only one image which will be enough to fool discriminator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if reason for this is small number of epochs the loop is going to work for hundreds epochs. To do this I will use google collab or kaggle resources for using gpu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another experiment is to check this code for Fashion MNIST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
